\section{Benchmarks}
\label{ildl:sec:benchmarks}
\label{ildl:sec:benchmarks:ad-hoc}

This section evaluates the experimental benefits of ADR transformations in targeted micro-benchmarks and in
the setting of a library and its clients.

We ran the benchmarks on an Intel |i7-4702HQ| quad-core processor machine with the frequency fixed at |2.2GHz|, and |2GB| of RAM, running the Oracle Java SE |1.7.0_80-b15| distribution on Ubuntu |14.04 LTS|. To avoid the noise caused by the just-in-time (JIT) compiler and garbage collection (GC) cycles, we measured the running times using the ScalaMeter benchmarking platform \cite{scalameter}, which warms up the Java Virtual Machine according to statistically rigorous performance evaluation guidelines \cite{rigorous-java-benchmarking}.

Our benchmarking platform, ScalaMeter, executes micro-benchmarks using the following recipe:
\begin{itemize}
  \item First, fork a new JVM;
  \item Execute the benchmark several times to warm up the JVM, only measuring the noise;
  \item When the noise drops below a threshold, execute the benchmark and gather measurements;
\end{itemize}


\noindent
For each benchmark run, we monitor:
\begin{itemize}
  \item The benchmark running time;
  \item GC cycles occurring during the run (in-benchmark);
  \item GC cycles occurring after the run (inter-benchmark);
\end{itemize}


\noindent
At the end of a cycle, we manually trigger a full GC cycle so the current run does not affect the next. The memory collected after the run (inter-benchmark) corresponds to the input and output data and any garbage produced by running the benchmarked code that was not automatically collected during its execution (in-benchmark).

This allows us to record the following parameters for each benchmark:

\begin{itemize}
  \item Benchmark running time (ms)
  \item In-benchmark garbage collected (MB)
  \item In-benchmark GC pause time (ms)
  \item Inter-benchmark garbage collected (MB)
  \item Inter-benchmark GC pause time (ms)
\end{itemize}


\noindent
Since the ADR transformation is directly related to memory layout and, thus, to memory consumption, we paid special attention to GC cycles. Please notice that the benchmark running time includes the in-benchmark GC pause but not the inter-benchmark GC pause. This allows us to separately measure the speedups gained by avoiding GC cycles and from other factors, such as:

\begin{itemize}
  \item Avoiding pointer dereferencing;
  \item Improving cache locality;
  \item Simplifying operations;
  \item Specializing operations;
  \item Lazyfying operations.
\end{itemize}


\noindent
For each benchmark, we broke down the transformation in several steps, which allowed us to quantify the exact contribution obtained by each transformation step. Unfortunately, due to space constraints, we cannot include the complete analysis here. Interested readers can review it in the accompanying artifact or on the project website \cite{ildl-plugin-wiki}.


\noindent
We chose representative micro-benchmarks in order to cover a wide range of transformations using the |adrt| scope:

\begin{itemize}
\item the greatest common divisor algorithm, presented in \S\ref{ildl:sec:problem};
\item least squares benchmark + deforestation \cite{wadler-deforestation};
\item averaging sensor readings + array of struct;
\item computing the first 10000 Hamming numbers.
\end{itemize}


\noindent
All benchmarks are fully automated and use the |adrt| markers and transformation description objects. We will proceed to explain the transformation in each benchmark, but, due to space constraints, the full descriptions are only available on the website.

\begin{table*}[t!]
  \centering
  \begin{tabularx}{\textwidth}{|g| *{6}{|Y}|} \hline
    \rowcolor{Gray}                                &               &                  & \multicolumn{2}{c|}{In-benchmark}    & \multicolumn{2}{c|}{Inter-benchmark} \\\cline{4-7}
    \rowcolor{Gray}\textbf{Benchmark}              & \textbf{Time} & \textbf{Speedup} & \textbf{Garbage}  & \textbf{GC time}  & \textbf{Garbage}  & \textbf{GC time} \\
    \rowcolor{Gray}                                &  (ms)         &                  & (MB)              & (ms)              & (MB)              & (ms)     \\ \hline
    10K GCD runs, original & 28.1 &    none &        0 &        0 &     13.5 &       13 \\
    10K GCD runs, class    & 12.5 &    2.2x &        0 &        0 &      2.5 &       10 \\
    10K GCD runs, boxed    & 15.0 &    1.9x &        0 &        0 &      8.7 &       11 \\
    10K GCD runs, unboxed  &  2.2 &   12.7x &        0 &        0 &      0.5 &        9 \\ \hline
  \end{tabularx}

  \caption{Greatest Common Divisor benchmark results.}
  \label{ildl:table:gcd}
\end{table*}

\subsubsection*{The Gaussian Greatest Common Divisor}
is the running example described in \S\ref{ildl:sec:problem} and used throughout the chapter. It is a numeric, CPU-bound benchmark, where the main slowdown is caused by heap allocations and GC cycles. We broke down the transformation into four steps, with the result shown in Table \ref{ildl:table:gcd}. None of the transformations triggered GC pauses during the measured runs, but they did produce different amounts of garbage objects:


\noindent
\textbf{The ``original'' benchmark} does not apply any transformation, thus modeling Gaussian integers using Scala's |Tuple2| class. Due to limitations in the specialization \cite{iuli-thesis, specialization-iuli} translation in Scala, the memory footprint of |Tuple2| classes is larger than it should be.


\noindent
\textbf{The ``class'' transformation} applies an |adrt| transformation which encodes Gaussian integers as our own |Complex| class, essentially retrofitting specialization. This obtains a 2x speed improvement and reduces the garbage by 5x:

\begin{lstlisting-nobreak}
case class Complex(_1: Int, _2: Int)
\end{lstlisting-nobreak}


\noindent
\textbf{The ``boxed'' transformation} encodes Gaussian integers as long integers, but keeps them heap-allocated. This is slower than having our own class since it requires encoding values into the long integer representation. To achieve boxing, we use |java.lang.Long| objects, which the Scala backend does not unbox. The additional value encoding produces a small slowdown and for unknown reasons increases the garbage produced.


\noindent
\textbf{The ``unboxed'' transformation} is the one shown throughout the chapter. It encodes Gaussian integers as |scala.Long| values, which are automatically unboxed by the Scala compiler backend. This brings a significant speedup to the benchmark, allowing execution to occur without any heap allocation, as explained in \S\ref{ildl:sec:ildl:method}. Compared to using pairs of integers, the speedup is almost 13x and the garbage is reduced by
27x.


\noindent
The transformation description objects for the three transformations above range between 30 and 40 lines of code and include more operations than necessary for the benchmark, such as addition, multiplication, multiplication with integers, subtraction, etc.


\subsubsection*{The Least Squares Method} takes a list of points in two dimensions and computes the slope and offset of a straight line that best approximates the input data. The benchmark performs multiple traversals over the input data and thus can benefit from deforestation \cite{wadler-deforestation}, which avoids the creation of intermediate collections after each |map| operation:

\begin{lstlisting-nobreak}
adrt(ListAsLazyList){
  def leastSquares(data: List[(Double, Double)]) = {
    val size = data.length
    val sumx = data.map(_._1).sum
    val sumy = data.map(_._2).sum
    val sumxy = data.map(p => p._1 * p._2).sum
    val sumxx = data.map(p => p._1 * p._1).sum
    ...
  }
}
\end{lstlisting-nobreak}

\noindent
The |adrt| scope performs a generic transformation from |List[T]| to |LazyList[T]|:

\begin{lstlisting-nobreak}
object ListAsLazyList extends TransformationDescription {
  def toRepr[T](list: List[T]): LazyList[T] = ...
  def toHigh[T](list: LazyList[T]): List[T] = ...
  // bypass methods
}
\end{lstlisting-nobreak}

The |LazyList| collection achieves deforestation by recording the mapped functions and executing them lazily, either when |force| is invoked on the collection or when a |fold| operation is executed. Since the |sum| operation is implemented as a |foldLeft|, the |LazyList| applies the function and sums the result without creating an intermediate collection.

To put the transformation into context, we explored several scenarios:

\begin{table*}[t!]
  \centering
  \begin{tabularx}{\textwidth}{|g| *{6}{|Y}|} \hline
    \rowcolor{Gray}                                &               &                  & \multicolumn{2}{c|}{In-benchmark}    & \multicolumn{2}{c|}{Inter-benchmark} \\\cline{4-7}
    \rowcolor{Gray}\textbf{Benchmark}              & \textbf{Time} & \textbf{Speedup} & \textbf{Garbage}  & \textbf{GC time}  & \textbf{Garbage}  & \textbf{GC time} \\
    \rowcolor{Gray}                                &  (ms)              &             & (MB)              & (ms)              & (MB)              & (ms)     \\ \hline
    LSM, original          & 8264 &    none &     1166 &     7547 &      809 &     5317 \\
    LSM, scala-blitz       & 3464 &    2.4x &      468 &     2936 &     1165 &     5236 \\
    LSM, adrt generic      &  429 &   19.3x &      701 &        3 &      933 &     5210 \\
    LSM, adrt miniboxed    &  280 &   29.5x &        0 &        0 &      701 &     5193 \\
    LSM, manual deforestation  &  195 &   42.4x &        0 &        0 &      702 &     5269 \\
    LSM, manual fusion     &   79 &  105.0x &        0 &        0 &      702 &     5282 \\ \hline
  \end{tabularx}

  \caption{Least Squares Method benchmark results.}
  \label{ildl:table:lslr}
\end{table*}

\noindent
\textbf{The ``original'' case} executes the least squares method on 5 million points without any transformation. Table \ref{ildl:table:lslr} shows that, on average, as much as 1.1 GB of heap memory is reclaimed during the benchmark run, significantly slowing down the execution. If it was not for the in-benchmark GC pause, the execution would take around 700ms, in line with the other transformations.

\noindent
What we can also notice is that, across all benchmarks, the input data occupies around 700MB of heap space and is only collected at the end of the benchmark. A back-of-the-envelope calculation can confirm this: each linked list node takes 32 bytes (2-word header + 8-byte pointer to value + 8-byte pointer to the next cell) and contains a tuple of 48 bytes (2-word header + two 8-byte pointers and two 8-byte doubles, due to limitations in specialization), which itself contains 16 bytes per boxed double. Considering 5 million such nodes, we have: $(32 + 48 + 2 \times 16) * 5 \times 10^6 = 560 \times 10^6$, approximately 560MB of data.


\noindent
\textbf{The ``blitz'' transformation} uses the dedicated collection optimization tool |scalablitz| \cite{scalablitz, scalablitz-paper} to improve performance. Under the hood, scalablitz uses compile-time macros to rewrite the code and improve its performance. Indeed, the tool manages to both cut down on garbage generation and improve the running performance of the code.


\noindent
\textbf{The ``adrt'' transformation} performs deforestation by automatically introducing |LazyList|s. This avoids the creation of intermediate lists and thus significantly reduces the garbage produced. We tried using two versions of |LazyList|: one using erased generics (adrt generic) and one using miniboxing \cite{miniboxing} specialization (adrt miniboxed).

The erased generic |LazyList| executed the code on par with the scalablitz optimizer but produced less garbage and the GC pause was much shorter (probably requiring a simple young-generation collection, not a full mark and sweep).

The miniboxed |LazyList|, on the other hand, both executed faster and did not produce any in-benchmark garbage. If we count in-benchmark GC pauses, the speedup produced by combining ``adrt'' scopes for deforestation and miniboxing for specialization is 29.5x compared to the original code. If we only count execution time, subtracting in-benchmark GC pauses, the speedup is 2.56x.

\noindent
\textbf{Manual transformations} complete the picture: in the ``deforestation'' transformation we write C-like while loops by hand to traverse the input list. We use four separate loops, to simulate the best case scenario for an automated transformation. The result is a 1.43x speedup compared to ``adrt miniboxed''.

The ``fusion'' manual transformation unites the four separate input list traversals into a single traversal. While this transformation cannot be applied unless we assume a closed world, it is still interesting to compare our transformation to a best-case scenario. The manual fusion improves the performance by 3.54x compared to ``adrt miniboxed''. However, what we can notice is that both ``adrt miniboxed'' and the manual transformations produce the exact same amount of garbage: 700MB.

In terms of programmer effort, the |LazyList| definition takes about 60 LOC and the transformation description object about 30 LOC. The difference between ``adrt erased'' and ``adrt miniboxed'' is the presence of |@miniboxed| annotations in the |LazyList| classes and in the description object.

\subsubsection*{The Sensor Readings} benchmark is inspired by the Sparkle visualization tool \cite{sparkle}, which is able to quickly display, zoom, transform and filter sensor readings. To obtain nearly real-time results, Sparkle combines several optimizations such as streaming and array-of-struct to struct-of-array conversions, all currently implemented by hand. In our benchmark, we implemented a mock-up of the Sparkle processing core and automated the array-of-struct to struct-of-array transform:

\begin{lstlisting-nobreak}
type SensorReadings = Array[(Long, Long, Double)]
class StructOfArray(arrayOfTimestamps: Array[Long],
                           arrayOfEvents:     Array[Long],
                           arrayOfReadings:   Array[Double])

object AoSToSoA extends TransformationDescription {
  def toRepr(aos: SensorReadings): StructOfArray = ...
  def toHigh(soa: StructOfArray): SensorReadings = ...
  ...
}
\end{lstlisting-nobreak}

In the benchmark, we have an array of 5 million events, each with its own timestamp, type and reading. We are seeking to average the readings of a single type of event occurring in the event array. Since our transformation influences cache locality, we had two different speedups depending on the event distribution:

\begin{itemize}
 \item Randomly occurring events are triggered with a probability of 1/3 in the sensor reading array;
 \item Uniformly occurring events appear every 3rd element, thus offering more room for CPU speculation.
\end{itemize}

Using the |adrt| scope to transform the array of tuples into a tuple of arrays allows better cache locality and fewer pointer dereferences. With random events, the ``adrt'' transformation produces a speedup of 1.8x. With uniformly distributed events, both the original and the transformed code run faster, yet resulting in a speedup of 5.7x.

In all four cases, the amount of memory allocated is approximately the same and no objects are allocated aside from the input data. Thus, the operation speedups are obtained through improving cache locality.

The transformation description object is 50 LOC and requires 20 additional LOC to define implicit conversions.

\begin{table*}[t!]
  \centering
  \begin{tabularx}{\textwidth}{|g| *{6}{|Y}|} \hline
    \rowcolor{Gray}                                &               &                  & \multicolumn{2}{c|}{In-benchmark}    & \multicolumn{2}{c|}{Inter-benchmark} \\\cline{4-7}
    \rowcolor{Gray}\textbf{Benchmark}              & \textbf{Time} & \textbf{Speedup} & \textbf{Garbage}  & \textbf{GC time}  & \textbf{Garbage}  & \textbf{GC time} \\
    \rowcolor{Gray}                                &  (ms)              &             & (MB)              & (ms)              & (MB)              & (ms)     \\ \hline
    array of struct, random & 55.5 &    none &        0 &        0 &      451 &       15 \\
    struct of array, random & 30.4 &    1.8x &        0 &        0 &      435 &       13 \\
    array of struct, uniform& 32.5 &    none &        0 &        0 &      454 &       16 \\
    struct of array, uniform&  5.7 &    5.7x &        0 &        0 &      433 &       19 \\ \hline
    10001-th number, original  & 6.56 &    none &        0 &        0 &       31 &       11 \\
    10001-th number, step 1 & 2.70 &    2.4x &        0 &        0 &       31 &       11 \\
    10001-th number, step 2 & 2.16 &    3.0x &        0 &        0 &       31 &       12 \\
    10001-th number, step 3 & 1.64 &    4.0x &        0 &        0 &       31 &       10 \\ \hline
  \end{tabularx}

  \caption{Sensor Readings and Hamming Numbers benchmark results.}
  \label{ildl:table:sparkle}

\end{table*}

\subsubsection*{The Hamming Numbers Benchmark} computes numbers that only have 2, 3 and 5 as their prime factors, in order. Unlike the other benchmarks, this is an example we randomly picked from Rosetta Code \cite{rosetta-code} and attempted to speed up:

\begin{lstlisting-nobreak}
adrt(BigIntToLong) {
  adrt(QueueOfBigIntAsFunnyQueue) {
    class Hamming extends Iterator[BigInt] {
      import scala.collection.mutable.Queue
      val q2 = new Queue[BigInt]
      val q3 = new Queue[BigInt]
      val q5 = new Queue[BigInt]
      def enqueue(n: BigInt) = {
        q2 enqueue n * 2
        q3 enqueue n * 3
        q5 enqueue n * 5
      }
      def next = {
        val n = q2.head min q3.head min q5.head
        if (q2.head == n) q2.dequeue
        if (q3.head == n) q3.dequeue
        if (q5.head == n) q5.dequeue
        enqueue(n); n
      }
\end{lstlisting-nobreak}

\begin{lstlisting-nobreak}
      def hasNext = true
      q2 enqueue 1
      q3 enqueue 1
      q5 enqueue 1
    }
  }
}
\end{lstlisting-nobreak}

An observation is that, for the first 10000 Hamming numbers, there is no need to use |BigInt|, since the numbers fit into a |Long| integer. Therefore, we used two nested |adrt| scopes to replace |BigInt| by |Long| and |Queue[BigIng]| by a fixed-size circular buffer built on an array. The result was an 4x speedup. The main point in the transformation is its optimistic nature, which makes the assumption that, for the Hamming numbers we plan to extract, the long integer and a fixed-size circular buffer are good enough. This is similar to what a dynamic language virtual machine would do: it would make assumptions based on the code and would automatically de-specialize the code if the assumption is invalidated. In our case, when the assumption is invalidated, the code will throw an exception.

As with other benchmarks, we broke down the transformation is several steps:


\noindent
\textbf{The ``original'' code} is the unmodified version from the Rosetta Code website, which we kept as a witness.


\noindent
\textbf{The ``step1'' code} uses |adrt| scopes to replace the |Queue| object with a custom, fixed-size array-based circular buffer. This collection specialization brings a 2.4x speedup without any memory layout transformation.


\noindent
\textbf{The ``step2'' code} uses |adrt| scopes to replace the |BigInt| object in both class |Hamming| and the circular buffer by boxed |java.lang.Long| objects. This additional range restriction brings an extra 1.25x speedup.


\noindent
\textbf{The ``step3'' code} replaces the |BigInt| objects by unboxed |scala.Long| values. This unboxing operation produces an additional 1.31x speedup, as fewer objects are created during the benchmark execution.

The conclusion is that, although the ADR transformation can be viewed as a memory layout optimization, it can additionally trigger more optimizations that bring orthogonal speedups, such as
specializing operations and collections.

For this example, the two transformation objects are 100 LOC and the circular buffer is another 20 LOC.


