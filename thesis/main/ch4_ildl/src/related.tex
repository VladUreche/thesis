\section{Related Work}
\label{sec:related}


Changing data representations is a well-established and time-honored programming need. Techniques for removing abstraction barriers have appeared in the literature since the invention of high-level programming languages and often target low-level data representations. However, our technique is distinguished by its automatic determination of when data representations should be transformed, while giving the programmer control of how to perform this transformation and on which scope it is applicable.

As discussed earlier, the standard optimizations that are closest to our approach are value classes~\cite{sip-value-classes} and class specialization~\cite{iuli-thesis,miniboxing}. These are optimizations
with great practical value, and most modern languages have felt a need for them. For instance, specialization optimizations have recently been proposed for adoption in Java, with full VM support~\cite{goetz-specialization}. Rose has an analogous proposal for value classes~\cite{rose-value-classes-vm,rose-value-classes-tearing} in Java. Unlike our approach, all the above are whole-program data representation transformations and receive limited programmer input (e.g., a class annotation).

Virtual machine optimizations often also manage to produce efficient low-level representations through tracing \cite{tracemonkey} or inlining and escape analysis \cite{escape-analysis-first-paper,stadler-escape-analysis}. Furthermore, modern VMs, such as V8, Truffle~\cite{graal} and PyPy~\cite{bolz-pypy-tracing-jit} attempt specialization and inference of optimized layouts. However, the ability to perform complex inferences dynamically is limited, and there is no way to draw domain-specific knowledge from the programmer. Generally VM optimizations are often successful at approaching the efficiency of a static language in a dynamic setting, but not successful in reliably exceeding it. \iv{They're very cool nevertheless.}

In terms of transformations, we already presented the Late Data Layout \cite{ldl} mechanism in the Scala setting. Similar approaches, with different specifics in the extent of type system and customization support, have been applied to Haskell~\cite{spj-unboxed-values}. Foundational work exists for ML, with Leroy~\cite{leroy-unboxed-objects} presenting a transformation for unboxing objects, with the help of the type system. Later work extends~\cite{thiemann-unboxed-objects-cps} and generalizes~\cite{shao-flexible-representation-analysis} such transformations. In terms of runtime-dispatched generics, we refer to the work on Napier88 \cite{morrison-napier88} and the TIL compiler \cite{tarditi-til,harper-intensional-type-analysis}.

In the specific setting of data structure specialization, the CoCo approach~\cite{Xu:2013:CSA:2524984.2524986} adaptively replaces uses of Java collections with optimized representations.  CoCo has a similar high-level goal as our techniques, yet focuses explicitly on collections only. Approaches that only target a finite number of classes (data structure implementations) can be realized entirely in a library. An adaptive storage strategy for Python collections \cite{bolz-python-strategies}, for instance, switches representations once collections become polymorphic or once they acquire many elements. The Scala Blitz optimizer uses macros to improve collection performance \cite{scalablitz-paper, scalablitz}.

Among mechanisms for extending an interface, such as extension methods, implicit conversions \cite{oliveira-implicit-calculus} and type classes \cite{wadler-typeclasses} we can also mention views, which allow data abstraction and extraction through pattern matching \cite{wadler-views}.

Multi-stage programming \cite{taha-intro} is another technique that optimizes the data representation. Its Scala implementation, dubbed lightweight modular staging, can both optimize and even re-target parts of a
program to GPUs \cite{tiark-lms,delite}. Yet, multi-stage programming scopes are not accessible from outside, making it impossible to call a transformed method or read a transformed value. Instead, the transformation scope is closed and nothing is assumed to be part of the interface. Hopefully, this will be improved by techniques such as the Yin-Yang staging front-end \cite{vojin-yy}, based on Scala macros \cite{eugene-macros}. Another type-directed transformation in the Scala compiler is the pickling framework \cite{heather-pickers}, also based on macros. Instead of transforming the data representation in-place, pickler combinators create serialization code that can efficiently convert an object to a wide range of formats.
