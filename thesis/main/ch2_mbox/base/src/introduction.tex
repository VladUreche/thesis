\section{Introduction}
\label{sec:Intro}

\topic{\newterm{Parametric polymorphism} allows programmers} to describe algorithms and data structures irrespective of the data they operate on. This enables code reuse and type safety. For the programmer, \newterm{generic code}, which uses parametric polymorphism, exposes a uniform and type safe interface that can be reused in different contexts, while offering the same behavior and guarantees. This increases productivity and improves code quality. Modern programming languages offer generic collections, such as linked lists, array buffers or maps as part of their standard libraries.

\topic{But despite the uniformity exposed to programmers, the lower level translation of generic code struggles with fundamentally non-uniform data.} To illustrate the problem, we can analyze the |contains| method of a linked list parameterized on the element type, |T|, written in the Scala programming language:  

\begin{lstlisting-nobreak}
 def contains(element: T): Boolean = ...
\end{lstlisting-nobreak}

When translating the |contains| method to lower level code, such as \newterm{assembly} or \newterm{bytecode} targeting a \newterm{virtual machine}, a compiler needs to know the exact type of the parameter, so it can be correctly retrieved from the stack, registers or read from memory. But since the list is generic, the type parameter |T| can have different bindings, depending on the context, ranging from a byte to a floating point number or a pointer to a heap object, each with different sizes and semantics. So the compiler needs to bridge the gap between the uniform interface and the non-uniform low level implementation. 

\topic{Two main approaches to compiling} generic code are in use today: heterogeneous and homogeneous. \newterm{Heterogeneous translation} duplicates and adapts the body of a method for each possible type of the incoming argument, thus producing new code for each type used. On the other hand, \newterm{homogeneous translation}, typically done with \newterm{erasure}, generates a single method but requires data to have a common representation, irrespective of its type. This common representation is usually chosen to be a heap object passed by reference, which leads to indirect access to values and wasteful data representation. This, in turn, slows down the program execution and increases heap requirements. The conversions between value types and heap objects are known as \newterm{boxing} and \newterm{unboxing}. A different uniform representation, typically reserved to virtual machines for dynamically typed languages, uses the \newterm{fixnum} \cite{fixnums-lisp} representation. This representation can encode different types in the same unit of memory by reserving several bits to record the type and using the rest to store the value. Aside from reducing value ranges, this representation also introduces delays when \newterm{dispatching} operations, as the value and type need to be unpacked. An alternative is the \newterm{tagged union} representation \cite{tagged-unions-lua}, which does not restrict the value range but requires more heap space.

\topic{C++ \cite{cxx-stroustrup} and the .NET Common Language Runtime \cite{ecma-dotnet, dot-net-generics} have shown that on-demand heterogeneous translations can obtain good performance} without generating significant amounts of low level code. However, this comes at a high price: C++ has taken the approach of on-demand compile-time template expansion, where compiling the use of a generic class involves instantiating the template, type checking it and generating the resulting code. This provides the best performance possible, as the instantiated template code is monomorphic, but undermines separate compilation in two ways: first, libraries need to carry source code, namely the templates themselves, to allow separate compilation, and second, multiple instantiations of the same class for the same type arguments can be created during different compilation runs, and need to be eliminated in a later linking phase. The .NET Common Language Runtime takes a load-time, on-demand approach: it compiles generics down to bytecode with type information embedded, which the virtual machine specializes, at load-time, for the type arguments. This provides good performance at the expense of more a complex virtual machine and lock-step advancements of the type system and the virtual machine implementation.

\topic{In trying to keep separate compilation and virtual machine backward compatibility, the Java programming language \cite{java-spec} and other statically typed JVM languages \cite{scala-www, kotlin-www, ceylon-www, x10-www} use homogeneous translations,} which sacrifice performance. Recognizing the need for execution speed, Scala \newterm{specialization} \cite{iuli-thesis} allows an \newterm{annotation-driven}, \newterm{compatible} and \newterm{opportunistic} heterogeneous transformation to Java bytecode. Programmers can explicitly annotate generic code to be transformed using a heterogeneous translation, while the rest of the code is translated using boxing \cite{java-erasure}. Specialization is a compatible transformation, in that specialized and homogeneously translated bytecode can be freely mixed. For example, if both a generic call site and its generic callee are specialized, the call will use primitive values instead of boxing. But if either one is not specialized, the call will fall back to using boxed values. Specialization is also opportunistic in the way it injects specialized code into homogeneous one. Finally, being annotation-driven, it lets programmers decide on the tradeoff between speed and code size.

\topic{Unfortunately the interplay between separate compilation and compatibility} forces specialization to generate all \newterm{heterogeneous variants} of the code during the class compilation instead of delaying their instantiation to the time they are used, like C++ does. Although in some libraries this behavior is desirable \cite{gil-adobe}, generating all heterogeneous variants up front means specializing must be done cautiously so the size of the generated bytecode does not explode. To give a sense of the amount of bytecode produced by specialization, for the Scala programming language, which has 9 primitive value types and 1 reference type, fully specializing a class like |Tuple3| given below produces $10^3$ classes, the Cartesian product of 10 variants per type parameter: 

\begin{lstlisting-nobreak}
 class Tuple3[A, B, C](a: A, b: B, c: C)
\end{lstlisting-nobreak}

\topic{In this paper we propose an alternative translation, called \newterm{miniboxing}, which relies on a very simple insight} to reduce the bytecode size by orders of magnitude: since larger value types (such as integers) can hold smaller value types (such as bytes), it is enough for a heterogeneous translation to generate variants for the larger value types. In our case, on the Java Virtual Machine, miniboxing reduces the number of code variants from 10 per type parameter to just 2: reference types and the largest value type in the language, the long integer. In the |Tuple3| example, miniboxing only generates $2^3$ specialized variants, two orders of magnitude less bytecode than specialization. Miniboxed code is faster than homogeneous code, as data access is done directly instead of using boxing. Unlike fixnums and tagged unions, miniboxing does not attach the type information to values but to classes and methods and thus leverages the language's static type system to optimize storage. Furthermore, the full miniboxing transformation eliminates the overhead of dispatching operations by using load-time class cloning and specialization (\S\ref{sec-classloading}). In this context, our paper makes the following contributions:  

\begin{itemize}
  \item Presents an encoding that reduces the number of variants per type parameter in heterogeneous translations (\S{}\ref{sec-miniboxing}) and the code transformations necessary to use this encoding (\S\ref{sec-mb-traf});
  \item Optimizes bulk storage (arrays) in order to reduce the heap footprint and maintain compatibility to homogeneous code, produced using erasure (\S{}\ref{sec-runtime});
  \item Utilizes a load-time class transformation mechanism to eliminate the cost of dispatching operations on encoded values (\S{}\ref{sec-classloading}).
\end{itemize}  

The miniboxing encoding can reduce duplication in any heterogeneous translation, as long as the following criteria are met:
\begin{itemize}
  \item The value types of the statically typed target language can be encoded into one or more larger value types (which we call \newterm{storage types}) - in the work presented here we use the long integer as the single storage type for all of Scala's primitive value types;
  \item Conversions between the value types and their storage type do not carry significant overhead (no-op conversions are preferable, but not required);
  \item The set of operations allowed on generic values in the language is fixed (similar to fixing the where clauses in PolyJ \cite{myers-polyj});
  \item All value types have boxed representations, in order to have a common data representation between homogeneous and miniboxed code. This representation is used to ensure compatibility between the two translations.
\end{itemize}

In order to optimize the code output by the miniboxing transformation, this paper explores the interaction between value encoding and array optimization on the HotSpot Java Virtual Machine. The final miniboxing transformation, implemented as a Scala compiler plug-in\footnote{Available at \url{http://scala-miniboxing.org/}.}, approaches the performance of monomorphic code, matches the performance of specialization, and obtains speedups of up to 22x over the current homogeneous translation, all with modest increases in bytecode size (\S{}\ref{sec-evaluation}).

The paper will first explain the specialization transformation (\S\ref{sec-generics}) upon which miniboxing is built. It will then go on to explain the miniboxing encoding (\S\ref{sec-miniboxing}), transformation (\S\ref{sec-mb-traf}), runtime support (\S\ref{sec-runtime}) and load-time specialization (\S\ref{sec-classloading}). It will finish by presenting the evaluation (\S\ref{sec-evaluation}), surveying the related work (\S\ref{sec-related}) and concluding (\S\ref{sec-conclusions}).  
